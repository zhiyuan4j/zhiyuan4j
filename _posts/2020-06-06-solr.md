---
layout: post
title:  "solr"
excerpt: "一些solr经验小记"
categories: [solr]
commnet: true
---

# Solr

**全文基于solr 8.x，本文所有代码只展示了核心部分，不是无脑可以直接复制的，不适合完完全全的小白，更适合有一丢丢使用经验的。**只是使用经验的总结，不是系统的整理介绍，系统的内容还请移步[官方文档](https://lucene.apache.org/solr/guide/)

### 关于索引数据

**推荐使用SolrJ(java api)，自己写程序索引，开发简单，灵活方便**

> Writing a custom Java application to ingest data through Solr’s Java Client API (which is described in more detail in [Client APIs](https://lucene.apache.org/solr/guide/8_5/client-apis.html#client-apis)). **Using the Java API may be the best choice** if you’re working with an application, such as a Content Management System (CMS), that offers a Java API.

之前使用过[DIH(Data Import Handler)](https://lucene.apache.org/solr/guide/8_5/uploading-structured-data-store-data-with-the-data-import-handler.html)进行mysql数据的索引，

结果写了个几百行join了二十几个表的一个sql，根本难以维护。所以DIH来索引数据有以下缺点：

1. 一些复杂字段极其考验后端开发的sql功底，有些字段的索引处理甚至是sql难以做到的，比如mysql里一个json字段的解析(mysql里要是硬想用position和substring两个函数解析json字段，就要求json字符串序列化null值，并且属性是有序的)
2. 一整个sql写完，往往有上百行，join了一大堆表，难以维护。
3. 索引速度慢。
4. 没办法很方便的更新单个索引。

用了SolrJ后，真香。接下来贴一些SolrJ的使用，最根基的增删改查：

### SolrJ相关API

```java
import org.apache.solr.client.solrj.beans.Field;
import java.util.List;

// 省略getter setter
// 存入solr里的模型，
// 最好不要有List<自定义类型>的属性在
// 因为solr对嵌套文档的支持不是很好
// 嵌套文档详情可以看Indexing Nested Child Documents
// https://lucene.apache.org/solr/guide/8_5/indexing-nested-documents.html
public class ProjectSolr {
    @Field private String id;
    @Field private String no;
    @Field private Integer projectId;
    @Field private Integer buildingId;
    @Field private Integer rentalUnitId;
    @Field private String provinceCode;
    @Field private String cityCode;
    @Field private String districtCode;
    @Field private List<Integer> marketIds;
    
}
```

```java
// 保存，删除，更新，查询，分组查询，分组统计
public class ProjectSolrDAO {
    private static Logger logger = Logger.getLogger(ProjectSolrDAO.class);
    private final static SolrClient solr = new HttpSolrClient.Builder(<URL>)
            .withConnectionTimeout(10000)
            .withSocketTimeout(60000)
            .build();

    public void save(ProjectSolr project) throws IOException, SolrServerException {
        final UpdateResponse updateResponse = solr.addBean(project);
    }
    
    public void deleteByProjectId(Integer projectId) throws IOException, SolrServerException {
       solr.deleteByQuery("projectId: 1122");
    }

    public void query(ProjectSolrQuery query) throws IOException, SolrServerException {
        
        final SolrQuery solrQuery = new SolrQuery();
        solrQuery.setStart(query.getPageIndex() * query.getPageSize());
        solrQuery.setRows(query.getPageSize());
        solrQuery.setQuery("id:1123 && marketIds:(122 336)");
        solrQuery.setParam("sort", "projectId asc, buildingId desc");

        final QueryResponse response = solr.query(solrQuery);
        // 总记录数
        response.getResults().getNumFound();
        // 查询结果
        List<ProjectSolr> result = response.getBeans(ProjectSolr.class);
    }
    
    // 按字段group的查询
    // 类似mysql的group，但是solr的group后是可以得到每一组的详细记录的
    // Result Grouping：https://lucene.apache.org/solr/guide/8_5/result-grouping.html
    public void groupQuery(ProjectSolrQuery query) throws IOException, SolrServerException {
        
        final SolrQuery solrQuery = new SolrQuery();
        solrQuery.setStart(query.getPageIndex() * query.getPageSize());
        solrQuery.setRows(query.getPageSize());

        solrQuery.setQuery("<查询条件>");
        solrQuery.setParam("sort", "<排序规则>");

        // 设置group参数
        solrQuery.set("group", true);
        solrQuery.set("group.field", "projectId");// 按projectId 分组
        solrQuery.set("group.limit", 50);
        solrQuery.set("group.ngroups", true);

        final QueryResponse response = solr.query(solrQuery);
        PageResult<ProjectSolrGroupDetailsDTO> pageResult = new PageResult<>();
        pageResult.setPageIndex(query.getPageIndex());
        pageResult.setPageSize(query.getPageSize());

        GroupResponse groupResponse = response.getGroupResponse();

        List<GroupCommand> values = groupResponse.getValues();

        // 可以断点查看groupResponse解析成自己的对象，以下贴个大概层次
        List<GroupCommand> values = groupResponse.getValues();

        // 一般情况size = 1
        for (GroupCommand command : values) {

            Integer totalCount = command.getNGroups();

            pageResult.setTotalRecordCount(totalCount);

            // 真正的项目分组数据信息
            // 之前group.limit = 50,所以这里的List<Group>的size就是50
            // 这里有个小技巧，可以用 documentObjectBinder.getBeans来直接获得List<ProjectSolr>
            // 以下包含了一些自己定义的业务类，代码贴出来仅展示了下结果解析的大概流程和层次结构
            List<Group> projectGroups = command.getValues();

            for (Group group : projectGroups) {
                DocumentObjectBinder documentObjectBinder = new DocumentObjectBinder();
        		List<ProjectSolr> projectSolrs = documentObjectBinder.getBeans(ProjectSolr.class, group.getResult());
            }

        }
       
    }
    
    public void update(ProjectSolr projectSolr) throws IOException, SolrServerException {
        SolrInputDocument updateDoc = new SolrInputDocument();
        // id一定要加
        updateDoc.addField("id", projectSolr.getId());
        updateDoc.addField
        updateDoc.addField
        updateDoc.addField
        updateDoc.addField
        //...不停的加更新字段

        UpdateRequest request = new UpdateRequest();
        request.add(updateDoc);
        request.process(solr);
    }
    
}
	
```

### 统计查询

**进阶重头戏**：如何实现，例如，打开一个租房列表，加载出每个类目下房子的数目：`青浦区(11)    长宁区(36)     徐汇区(999)`，这些11，36，999统计数字怎么用solr查询出来？

**关键词**：[JSON FACET API](https://lucene.apache.org/solr/guide/8_5/json-facet-api.html)

JSON FACET 跟普通FACET比更强大，因为可以用上很多函数，从而对字段进行变形，去重满足各种各样的需求。我开发时就需要用到`uniqueCount`这个函数去重

直接写这个查询的话是这么个字符串：

`json.facet={marketCategories:{field:marketIds,type:terms,limit:100,facet:{uniqueCount:"unique(projectId)"}},districtCategories:{field:districtCode,type:terms,facet:{uniqueCount:"unique(projectId)"}}}`

这里统计了两个维度，一个是每个子市场的数量，一个是每个区的数量

最里面那层`facet`的值可以用上很多solr的内置函数，比如这里我们就需要对每个区的projectId进行去重

solrj的写法:

```java
public List<ProjectRegionCount> queryRegionCount(ProjectSolrQuery query) throws IOException, SolrServerException {

    	// 这里构建facet是关键
        final TermsFacetMap districtFacet = new TermsFacetMap("districtCode").setLimit(100).withStatSubFacet("uniqueProjectCount", "unique(projectId)");
        final TermsFacetMap marketFacet = new TermsFacetMap("marketIds").setLimit(100).withStatSubFacet("uniqueProjectCount", "unique(projectId)");

    	// 在当前query的筛选条件下，每个区有多少个满足的项目，每个子市场有多少个满足的项目
        final JsonQueryRequest request = new JsonQueryRequest()
                .setQuery(ProjectSolrQueryBuilder.build(query))
                .withFacet("districtFacet", districtFacet)
                .withFacet("marketFacet", marketFacet);

        QueryResponse response = request.process(solr);

        NestableJsonFacet jsonFacetingResponse = response.getJsonFacetingResponse();

    	// 可以debug调试jsonFacetingResponse，来一步步解析这个结果
    	// 以下包含了一些自己定义的业务类，代码贴出来仅展示了下结果解析的大概流程和层次结构
        BucketBasedJsonFacet districtFacetResult = jsonFacetingResponse.getBucketBasedFacets("districtFacet");

        BucketBasedJsonFacet marketFacetResult = jsonFacetingResponse.getBucketBasedFacets("marketFacet");

	    List<ProjectRegionCount> projectRegionCounts = Lists.newArrayList();
        projectRegionCounts.addAll(processFacetResult(districtFacetResult, RegionType.DISTRICT));

        projectRegionCounts.addAll(processFacetResult(marketFacetResult, RegionType.MARKET));

        return projectRegionCounts;

    }

	// 以下包含了一些自己定义的业务类，代码贴出来仅展示了下结果解析的大概流程和层次结构
    private List<ProjectRegionCount> processFacetResult(BucketBasedJsonFacet bucketBasedJsonFacet, RegionType regionType) {

        if (bucketBasedJsonFacet == null) {
            return Lists.newArrayList();
        }

        List<ProjectRegionCount> projectRegionCounts = Lists.newArrayList();

        List<BucketJsonFacet> buckets = bucketBasedJsonFacet.getBuckets();

        for (BucketJsonFacet facet : buckets) {

            String key = String.valueOf(facet.getVal());
            int uniqueProjectCount = (int) facet.getStatValue("uniqueProjectCount");
            projectRegionCounts.add(buildProjectRegionCount(key, uniqueProjectCount, regionType.value));

        }

        return projectRegionCounts;
    }
```

### 个性化查询

根据用户行为，影响查询结果已经是很常见的需求了，我是通过[Function Queries](https://lucene.apache.org/solr/guide/8_5/function-queries.html)实现的。

比如用户看了10个房子，都是青浦区的，面基都是300-1000平的厂房，那么我们可以认为用户对青浦区的这个面积区间的房子感兴趣，当用户在随机浏览时，我们就会将原先的更新时间排序，改为综合地区和面积的个性化排序算法。举个工作中用到的个性化排序的一小段，`{x}`代表了索引的某个字段，`%s`实际中是一些数值，本质上就是将用户行为相关字段的值通过`function query`中的一些函数，计算成一个可以排序的数值

`sum(if(and(gte({0},%s),lte({0},%s)),1000,0),if(and(gt({0},%s),lte({1},%s)),100,0)) desc`

具体函数可以移步官网查看：[传送门](https://lucene.apache.org/solr/guide/8_5/function-queries.html)

至此感觉solr的个性化查询用这种方法还是有点不优雅，毕竟这个写出来的sort，函数一层包一层让人头晕，不知道有没有什么其他方式，欢迎留言讨论

### 学习方法

可以发现solrj的增删改的api还是比较简单的。

solr的文档写的还是相当不错的，如果遇到了solr使用上的相关问题，我推荐的解决步骤是

1. 先通过搜索引擎搜索你的问题

   如果能直接解决你的问题最好，不能解决的话，找到几个频繁出现的关键词

2. 根据这个关键词，去solr官方文档里慢慢去学习相关内容，不理解的概念，内容多动手实践

一上来直奔官方文档，对于不怎么熟悉文档结构的来说可能会比较耗时

我这个json facet实现分组统计就是这么解决的，一开始哪能想到分组统计和json这个字眼能扯上关系，但是搜索引擎频繁出现这个词，于是仔细研读了JSON FACET API相关内容，再调整了搜索词，如此往复一步步就将问题抽丝剥茧解决了